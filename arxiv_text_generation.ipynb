{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arxiv_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X3AmemUMJ1x8",
        "pRG0kLuDx7ik",
        "-KaEL8yg5P2u",
        "I-YgaB5QI_Xi",
        "b6foowUKI6to"
      ],
      "mount_file_id": "1NMV_uytNOaoFH36L8bx0LEOpMiZCMA5a",
      "authorship_tag": "ABX9TyNWkZAE8/C32TkX/iuuEWsf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavo-medinav/char-rnn-arxiv-simple/blob/main/arxiv_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24xGqUtJvXhx"
      },
      "source": [
        "# Text generation for abstracts of scientific articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWxcxTP2vf0y"
      },
      "source": [
        "This notebook puts forward an implementation of a minimal language model for text generation of abstracts of scientific articles using a recurrent neural network. This is implemented at character level, including not only alphanumeric chacters but also punctuation and symbols used for typing mathematical expressions in latex, such as $$.\n",
        "\n",
        "The architecture includes an embedding layer to learn representations of characters in the text, thus, no pre-learnt embeddings are required.\n",
        "This minimal example makes use of two layers of LSTMs stacked on top of each other, where the state of the cells at each time-step is passed forward (many-to-many).\n",
        "The final layer is a fully connected dense layer to model the probability distribution over the vocabulary (characters). Rhe problem can be regarded as a classification problem where the number of categories is the size of the vocabulary.\n",
        "Thus, the loss function is selected to be categorical cross-entropy, where each example in the training set belongs to a single category.\n",
        "\n",
        "The model was trained on 100k abstracts from papers in the arXiv across all categories, taking about 8 hours of training to complete with the GPU provided by google colabs. The tained model can autocomplete words and generate syntactically correct sentences, although it lacks semantinc understanding and does displays limited long-term memory. The notebook outlines each step in the process and demonstrates the capabilities and limitations of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3AmemUMJ1x8"
      },
      "source": [
        "## 1. Import dataset from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkq-SNfqxCpo"
      },
      "source": [
        "To make use of the Kaggle API, we must upload our authentication key (see your Kaggle profile to generate an API token)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpUYzRA2GMzN"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI7bqTmHGOVL",
        "outputId": "dd235cf1-d8ad-40d3-96c4-3f64c50e1a45",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "files.upload();"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-366661e9-83ce-4edb-ae79-d2cc03fa9f0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-366661e9-83ce-4edb-ae79-d2cc03fa9f0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMVJ_Cc4xV49"
      },
      "source": [
        "By the default, the API looks for the authentication key in '/root/.kaggle', so we must make sure to move the file to that location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq-mjde6HZpt"
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgEmVnZ5KCyC"
      },
      "source": [
        "Now we can downlaod the data set. We'll be looking at the arXiv meta-data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXldPoFRFNw3",
        "outputId": "b031113d-bae1-40c4-e2bc-3a275c240536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle datasets list -s arxiv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "ref                                                        title                                              size  lastUpdated          downloadCount  \n",
            "---------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "Cornell-University/arxiv                                   arXiv Dataset                                     902MB  2020-11-08 00:52:17           4062  \n",
            "neelshah18/arxivdataset                                    ARXIV data from 24,000+ papers                     18MB  2018-03-31 03:47:25           1698  \n",
            "prasunroy/natural-images                                   Natural Images                                    342MB  2018-08-11 18:24:11          10524  \n",
            "rmisra/news-headlines-dataset-for-sarcasm-detection        News Headlines Dataset For Sarcasm Detection        3MB  2019-07-03 23:52:57          19412  \n",
            "tayorm/arxiv-papers-metadata                               Arxiv Papers Metadata Dataset                       4GB  2019-11-24 22:22:24            185  \n",
            "shujian/arxiv-nlp-papers-with-github-link                  Arxiv NLP papers with Github link                  45KB  2019-01-24 04:03:01            194  \n",
            "steliosdatascientist/covid19-arxiv-research-papers         COVID-19 : ArXiv Research Papers                   46KB  2020-05-29 10:04:21             15  \n",
            "shayanfazeli/heartbeat                                     ECG Heartbeat Categorization Dataset               99MB  2018-05-31 18:47:34          18224  \n",
            "peterwittek/scirate-quant-ph                               SciRate quant-ph                                   11MB  2017-02-13 08:42:11            233  \n",
            "camaskew/baseline-landmark-retrieval-model                 Baseline Landmark Retrieval Model                 166MB  2020-07-01 00:01:24            248  \n",
            "mksaad/arxiv-papers-2010-2020                              arXiv papers 2010 2020                             29MB  2020-08-09 05:19:06             24  \n",
            "mrisdal/open-exoplanet-catalogue                           Open Exoplanet Catalogue                          123KB  2017-06-08 19:59:22           2889  \n",
            "andrewmvd/isic-2019                                        Skin Lesion Images for Melanoma Classification      9GB  2020-05-28 05:11:34           1080  \n",
            "khoongweihao/covid19-xray-dataset-train-test-sets          COVID-19 Xray Dataset (Train & Test Sets)          84MB  2020-03-19 01:49:56           1953  \n",
            "yoctoman/shcxr-lung-mask                                   Lung Masks for Shenzhen Hospital Chest X-ray Set   20MB  2018-03-03 13:29:33           1998  \n",
            "BengaliAI/numta                                            NumtaDB: Bengali Handwritten Digits                 2GB  2018-08-14 03:08:59           1813  \n",
            "louise2001/quantum-physics-articles-on-arxiv-1994-to-2009  Quantum Physics articles on Arxiv 1994 to 2009     31MB  2020-06-02 13:34:34             62  \n",
            "mdepak/fakenewsnet                                         FakeNewsNet                                        17MB  2018-11-02 19:08:58           2063  \n",
            "ttahara/resnest50-fast-package                             Pytorch ResNeSt50-Fast                            692MB  2020-07-01 14:16:01            859  \n",
            "luisblanche/covidct                                        COVID-19 Lung CT Scans                             86MB  2020-04-09 12:08:48           1643  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbe8lbg0xnsS"
      },
      "source": [
        "The following line will start the download, which should not take too long"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9fCl_JkILjM",
        "outputId": "4ec9888f-3638-4325-f51a-d43f975a383d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle datasets download -d 'Cornell-University/arxiv'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading arxiv.zip to /content\n",
            "100% 898M/902M [00:29<00:00, 33.4MB/s]\n",
            "100% 902M/902M [00:29<00:00, 32.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAa_gSS7KOCy"
      },
      "source": [
        "Unzip the file to access the contents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVMRnpI2IjaU"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/arxiv.zip','r') as file:\n",
        "  file.extractall('/content/')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8exb6biYxymJ"
      },
      "source": [
        "Now we should have in our directory the dataset in a JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUXI-UPwJEAZ",
        "outputId": "47466d2b-b647-4d5f-a0ed-a9d4c95f94ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arxiv-metadata-oai-snapshot.json  arxiv.zip  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRG0kLuDx7ik"
      },
      "source": [
        "## 2. Load and transform the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "earzvdLDyA08"
      },
      "source": [
        "The dataset is too large to load all at once. Use a generator to read the records one at a time. Moreover, a little data-cleaning is required, as some of the abstract may contain characters will want to remove. Therefore, let's import the regular expressions module to clean the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFB7mSaapad_"
      },
      "source": [
        "import json\n",
        "import re\n",
        "import string\n",
        "import itertools\n",
        "import numpy as np"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VP3x6orAWak"
      },
      "source": [
        "Since this is going to be a character-level model, the vocabulary is known beforehand, the set of alphanumeric characters, whitespace characters and special characters. Thus, it can be loaded a priori from the 'string' module. The vocabulary can then be used to create lookup tables mapping characters to indices and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP5tYUlMrDtj"
      },
      "source": [
        "vocab = [n for n in string.printable]\n",
        "vocab_size = len(vocab)\n",
        "char2idx = {v:idx for idx,v in enumerate(vocab)}\n",
        "idx2char= np.array(vocab)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYPN9I7zBl_"
      },
      "source": [
        "The dataset contains a lot of records. We can control how many records we want to load by using itertools to define an iterator with a fixed start and fixed end.\n",
        "\n",
        "At this point, you should load a few examples and perform some exploratory data analysis to understand what the data set contains. In this example we are only interested in the abstracts of the papers, thus, we will not pay attention to any of the other fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1n6iQQohan4"
      },
      "source": [
        "gen_json = (json.loads(line) for line in itertools.islice(open('arxiv-metadata-oai-snapshot.json','r'),10))\n",
        "temp = []\n",
        "for line in gen_json:\n",
        "  temp.append(line['abstract'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nehh6-cSAzxS",
        "outputId": "4c3a49fe-a0be-43d1-a187-c60dfd5c35c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "temp[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZGbsTAsAqK9"
      },
      "source": [
        "Going through the examples, you will have noticed a few things:\n",
        "1. All abstracts start with 2 blanks and end with a newline character.\n",
        "2. Newline characters are included within the text for aesthetic purposes.\n",
        "3. Abstracts use latex to type mathematical expressions, which are enclosed in $$. These expressions also make use of the back-slash '\\', underscore '_' and the caret (hat) '^' characters, and may include all types of parenthesis, i.e. '()'. '[]', and '{}'.\n",
        "4. In a few examples, the text has been corrupted and non-printable characters appear. For instance, in one exampple, \"don't\" is rendered as \"donâ\\x80\\x99t\".\n",
        "\n",
        "These characteristics may introduce some noise to the data. While it may be true that a healthy degree of noise can naturally help prevent overfitting, we don't want the model to learn spurious patterns. Thus, some transformations are in order to clean the data.\n",
        "\n",
        "1. Newline characters within the text are removed. In turn, an additional newline character is appended at the end, such that all abstract start with two blank spaces and end with two newline characters.\n",
        "2. Characters resulting from corrupted text are transformed back to their original meaning. This is inferred from reading the examples.\n",
        "\n",
        "It is straightfoward, if somewhat tedious, to find the relevant instances of corrupted text. The following cell performs the necessary transformations on the first 100k records. Note that further corrupted characters may appear beyond this and must be checked manually if more examples are to be included.\n",
        "\n",
        "Finally, the characters are represented as indices using the lookup table previously defined from the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jio4dktzrHZW"
      },
      "source": [
        "num_examples = 100000\n",
        "gen_json = (json.loads(line) for line in itertools.islice(open('arxiv-metadata-oai-snapshot.json','r'),num_examples))\n",
        "abs_list = []\n",
        "for line in gen_json:\n",
        "  abs = line['abstract']\n",
        "  abs = re.sub(r'(\\S)\\s+(\\S)',r'\\1 \\2',abs).replace('\\n','\\n\\n')\n",
        "  abs = abs.replace('â\\x80\\x99',\"'\")\n",
        "  abs = abs.replace('\\x7f',\"\")\n",
        "  abs = abs.replace('â\\x88\\x9e',\"'\")\n",
        "  abs = abs.replace('â\\x89¤',\"'\")\n",
        "  abs = abs.replace('â\\x80\\x94',\"'\")\n",
        "  abs = abs.replace('â\\x80\\x93',\"-\")\n",
        "  for k in abs:\n",
        "    abs_list.append(char2idx[k])\n",
        "\n",
        "abs_list = np.array(abs_list)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9B3doGEsHcM",
        "outputId": "1e930336-1305-4b33-c305-b1657adfc0fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "abs_list.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80064734,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KaEL8yg5P2u"
      },
      "source": [
        "## 3. Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WXwVX-w5UpX"
      },
      "source": [
        "Next we can initialise the model. This is done using the keras API with tensorflow on the backend. We will use the Embedding, LSTM and Dense layers. Alternatively, you can replace LSTM with GRU which is faster to train. We also import os now as this will be used for setup up the checkpoint during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub1n16vGg57X"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04ooNibK5ryF"
      },
      "source": [
        "The strategy for training the model will be dividing the text into non-overlapping fixed-length sequences. The model will be trained to predict the following word within each sequence. Thus, for each sequence there is a training and a target sequence, where the target is just the sequence shifted one character forward.\n",
        "\n",
        "At this point, we need to choose the length of the sequences. Scientific writting tends to containg longer sentences than other texts, as technical expressions are usually longer and sentences need to be precise in meaning to avoid ambiguities. Therefore, a sequence of 150 characters can be chosen based on this intuition. You can experiment with different lenghts and verify the results.\n",
        "\n",
        "The training, which makes use of gradient descent, is performed using mini-batch. This means that the training examples are fed in blocks containing a fixed number of examples. The batch size impacts training speed and accuracy. Too small or too large values can be slow to train. The optimum value is not apriori known and this is another hyper-parameter to experiment with. Moreover, it has been noted that large batch sizes may lead to poorer generalisation capability if the learning rate is not adjusted accordingly. In this case, a value of 256 is chosen as initial guess. You can experiment recording training speed and performance using different batch sizes.\n",
        "\n",
        "The following cell prepares the dataset to use for training:\n",
        "1. The dataset is intiatlised using the Dataset class from the Tensorflow module. This allows for easy manipulation of the data. \n",
        "2. The text is then separeted into sequences\n",
        "3. Training and target sets are created\n",
        "4. The examples are shuffled and packed into batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGNGAqJIonzC"
      },
      "source": [
        "seq_len = 150\n",
        "batch_size = 256\n",
        "dataset = tf.data.Dataset.from_tensor_slices(abs_list)\n",
        "dataset = dataset.batch(seq_len+1,drop_remainder=True)\n",
        "dataset = dataset.map(lambda x: (x[:-1],x[1:]))\n",
        "dataset = dataset.shuffle(1000).batch(batch_size,drop_remainder=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK-g6gC3qa_4",
        "outputId": "45ab6037-049c-438e-cc7c-98924b5b87dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 150), (256, 150)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBH27JM9_WCB"
      },
      "source": [
        "The model can now be specificied using the Sequential model class from Keras. This minimal example includes four layers.\n",
        "\n",
        "The first is an Embedding layer. This layer learns a representation of the characters in a vector space of some dimension. The embedding dimension is the third hyper-parameter so far introduced. Larger dimensions allow for representations that capture more structure, however, they also increase the number of parameters to train. In principle, transfer-learning could be used by loading learnt representations and thus saving training time.\n",
        "\n",
        "The second and third layers are made of LSTMs, recurrent units whose current state and output depend not only on the inputs but on the previous state. The number of cells can be tuned to increase the complexity of the model. Note that return_sequences is set to True, indicating that the cells pass forward their state at each time step (many-to-many mode), instead of just returning the state at the last time step (many-to-one mode). The 'stateful' parameter will be set to False during training but can be turned on for generating text later on. In this mode, the internal state of the cells is randomly initialised at the start of each batch. Note that since we have shuffled the training examples and we are assuming that 150 characters is enough context to predict the next one, it would not make sense to train with 'stateful' in this case.\n",
        "\n",
        "The fourth layer is a fully connected dense layer with the number of cells given by the vocabulary size. The activation values from this layer will be passed through a softmax function so they can be interpreted as the probability distribution over the space of characters. Note that the activation function is not included in here as it is more efficient to apply it when the loss is computed.\n",
        "\n",
        "The loss is the categorical cross-entropy loss. The function 'SparseCategoricalCrossentropy', since the targets are sparse vectors. This saves resources on memory as it is not necessary to load all the elements, just the index where the vectors are non-zero. Note the option 'from_logits' is set to True, indicating that the softmax function is to be applied to the result of the last layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edULLcPBsJ4J"
      },
      "source": [
        "def make_model(vocabulary_size,embedding_dimension,rnn_units,batch_size,stateful):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocabulary_size,embedding_dimension,\n",
        "                      batch_input_shape=[batch_size,None]))\n",
        "  model.add(LSTM(rnn_units,return_sequences=True,stateful=stateful))\n",
        "  model.add(LSTM(rnn_units,return_sequences=True,stateful=stateful))\n",
        "  model.add(Dense(vocabulary_size))\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer='adam',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XokikW29HgQS"
      },
      "source": [
        "The embedding dimension is set to 256 and the number of cells per layer, to 1024"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiPJX15ws2el",
        "outputId": "1c57c2e6-3302-4a9d-846e-0d28b0fea646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "emb_dim = 256\n",
        "rnn_units = 1024\n",
        "model = make_model(vocab_size,emb_dim,rnn_units,batch_size,False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (256, None, 256)          25600     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (256, None, 1024)         5246976   \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (256, None, 1024)         8392704   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (256, None, 100)          102500    \n",
            "=================================================================\n",
            "Total params: 13,767,780\n",
            "Trainable params: 13,767,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-YgaB5QI_Xi"
      },
      "source": [
        "## 4. Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVk49bL4HrCn"
      },
      "source": [
        "It will be useful to setup checkpoints during training so the weights will be saved at the end of each epoch. In the following, the directory where the check points are saved is declared. Then, the filename of the checkpoints is given, keeping the epoch number as a variable. To implement this in training, a callback is created using 'ModelCheckpoint' from 'callbacks'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T8uDw8gtC2W"
      },
      "source": [
        "checkpoint_dir = '/content/training_checkpoints/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,'chkpt_{epoch}')\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_prefix,\n",
        "                                                         save_weights_only=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzBo9ubaIM8y"
      },
      "source": [
        "Train the model using 10 epochs and the callback previously defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJIBWDeBdpsZ"
      },
      "source": [
        "model.fit(dataset,epochs=10,callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdlpDZSeIUIj"
      },
      "source": [
        "Before using the model to generate text, we need to make a technical adjustment. Once the model has been constructed, the batch size cannot be changed. Thus, we need to build a new model with the batch size we want to use. In this case, a batch size of 1 is enough as we will only feed in one piece of text at a time. This time 'stateful' can be set to True, as in theory we could  want to feed several lines of text sequentually. The weights can be loaded from the latest checkpoint. Make sure that the path to the latest checkpoint is the correct one. In my case, after training I moved my checkpoints to my google drive, as local files are deleted when the colab notebok is closed. The model is built by passing an empty example of the appropriate shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjZqnTH1GLup"
      },
      "source": [
        "# Change this to the directory where you saved your weights\n",
        "checkpoint_dir = '/content/drive/My Drive/nlp_projects/arxiv_text_generation/training_checkpoints'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz-_7D3Ri2rL"
      },
      "source": [
        "You can verify the filename of the latest checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEee8WzFGNNm",
        "outputId": "9f1d640d-35eb-4285-80c7-959ebfb88391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/nlp_projects/arxiv_text_generation/training_checkpoints/chkpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2XQoKCqvWFa",
        "outputId": "7720052f-f25b-4d08-cd20-0fd1aed6c50b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = make_model(vocab_size,emb_dim,rnn_units,1,True)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (1, None, 256)            25600     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (1, None, 1024)           8392704   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (1, None, 100)            102500    \n",
            "=================================================================\n",
            "Total params: 13,767,780\n",
            "Trainable params: 13,767,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0bWUaB5I3TN"
      },
      "source": [
        "Optionally, you can save the full model in an HDF5 file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8TTyVM6h1pK"
      },
      "source": [
        "model.save('/content/drive/My Drive/nlp_projects/arxiv_text_generation/model_13p8M_parameters.hdf5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6foowUKI6to"
      },
      "source": [
        "## 5. Generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTeWRZLlJF5j"
      },
      "source": [
        "The model can now be used to generate text. To do this, we can pass a string to act as a seed for the text we want to generate. Note this should be converted to the index representation using the table previously created. The following function takes care of this by converting a given string to the index representation, adding an artificial batch dimension of one, and running predictions on a loop until the desired number of characters is generated.\n",
        "\n",
        "The next character is predicted by drawing at random from the probability distribution returned by the model. Note that since the targets were shifted sequences, the model outputs a vector of lenth 150 with probability distributions for each character in the sequence. We are only interested in the last one, i.e., the probability distribution of the unseen character.\n",
        "\n",
        "The predicted character is used as the input in the next iteration. Note that the state of the LSTM cells is reset at the start of each independent prediction but it remembered while predicting a sequence of characters. In other words, if you call the function more than once, it is assumed that each call is independent on the previous ones.\n",
        "\n",
        "If you want the model to remember what it saw in previous calls, you can comment out the line for modelreset_states(). This could be, for example, if all calls are part of the same sequence of text. For example, if you let the model automplete some words of your writing in a long document, alternating between human input and machine prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VodbDXNvMEk"
      },
      "source": [
        "def generate_text(model,seed,num_characters):\n",
        "  seed_text = tf.expand_dims([char2idx[k] for k in seed],0)\n",
        "  generated_text = []\n",
        "  model.reset_states()\n",
        "  for n in range(num_characters+1):\n",
        "    result = tf.random.categorical(model(seed_text)[0,-1:],num_samples=1)\n",
        "    result = result[0,0].numpy()\n",
        "    generated_text.append(result)\n",
        "    seed_text = tf.expand_dims([result],0)\n",
        "  return ''.join(idx2char[generated_text])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmToYlosKdh8"
      },
      "source": [
        "Next we can try some different examples to see how good or bad the model performs. We'll give the model some initial text and call it 5 times to predict the next 100 characters. We start with a simple test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuCv3pShgDMP",
        "outputId": "2d30a3b8-8da7-41b7-d1f4-0153376331ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Can the model guess obvious characters/words?\n",
        "seed = (\"This is a short string to test if the model knows what the next character sh\")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "are both the dipole moment. Based on these assumptions, we show how ZAMO is that the source points on\n",
            "ould be observable in less than two of only one of the variables Vega sup.This paper addresses the ap\n",
            "ould invaled a given almost sure constant. However for which we have two types of Caucations the topo\n",
            "ows a classical warping coefficient. Our approach is modeled by calculating arbitrary functional form\n",
            "ould be valid against one and histosized (i.e. cooperative) function. We extend and transform the sma\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlPxmZqPoyls"
      },
      "source": [
        "It correctly autocomplets \"sh-\" to \"share\", \"should\" and \"shows\", which could be possible options. Given the context, \"should\" should be favoured, and it does appear 3/5 times. Can it predict an 'obvious' word based on the previous ones?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iro1fFPAgPbL",
        "outputId": "9ed78332-bc79-4323-ddd7-b982293c1c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Can it guess obvious characters/words?\n",
        "seed = (\"This is a text about Quantum Field \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Theory (CDMFT). The quantum analysis of an upper bound on the character expressing the coefficients e\n",
            "Theory. The paper concludes by incorporating symmetric double sets of the projection of the ideal of \n",
            "(CQF) is a buffer system, and is not an enhanced channel via an antagonia which capability and quanti\n",
            "Evaluation Formula (QMTs) to anharmonic DLAs).In this work we prove that all dedicated systems engang\n",
            "Nonestatic Welping group combines the optimal detector design techniques using Monte Carlo studies to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih8T9XmWpNg9",
        "outputId": "4c055ce8-6c59-4178-cb4f-e8a56ce38881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Can it guess obvious characters/words?\n",
        "seed = (\"Einstein introduced the theory of General \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relativity and electromagnetic fluxes. In this respect, we introduce the study of stochastic deformat\n",
            "Relativity, this reduction takes place as quasi-local the density enhanced dynamics with a definite q\n",
            "Relativity, when the dark energy coupless type 1 by slower cascaded cosmology with an accelerated cos\n",
            "Relativity higher order at infinite barrier and coordinates.We review how the strongly coupled theory\n",
            "Relativity or state transitions.Recent proofs of the orbifold compactification of a complex projectiv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMWKbJmFpks2",
        "outputId": "7400e8dd-348e-4427-8e76-37c2f091441e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Can it guess obvious characters/words?\n",
        "seed = (\"The results of the experiment indicate that the null hypothesis can be \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "included in the previous calculations and how creation of silicon diodes to form target states is des\n",
            "proved either in terms of the kinetic dependence of the dissipation function of an individual atom la\n",
            "reconstructed from 5 yr-emission. The X-ray and X-ray light curves and photospheric dynamical cosmic \n",
            "supposed to jet carryin different properties associated with $f_{\\rm H1}$, demonstrating that miscold\n",
            "suppressed using NLTE model.In this paper, we investigate dynamics of a chain octage of asymmetric nu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDuZuE60pwp_",
        "outputId": "a1296b18-7621-4c11-b525-d67b955f08e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Can it guess obvious characters/words?\n",
        "seed = (\"The gradient of the potential is computed by taking the derivative of the field with \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "respect to an element.\n",
            "  One kind of equation is the total height function to Berry within the framew\n",
            "respect to the slip operator and some further hotter distributions. In this case we strengthen the sc\n",
            "the result of a condition on a Chern chase of the interior is given. We present a dynamical model whi\n",
            "one of the boundary conditions on the equation ${\\cal M}^{w,t} = \\frag{g}q(M)$, which is the sharp ma\n",
            "the knot initial state equation. To this end, we address lack of solutions to dimension reductions in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xymHjIQJqkXz"
      },
      "source": [
        "It seems to do well with proper nouns such as QFT and GR, but not too well in other cases. We would expect a null hypothesis to be rejected, not \"included\". However, the model does predict verbs in the past participle form, ending in \"-ed\", which are syntactically correct. In the second example, the fairly common phrase \"with respect to\" is correctly autocompleted 2/5 times. The alternatives are also syntactically correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waZVN4swtSvb"
      },
      "source": [
        "Next we can test if the model is sensitive to how initial much context it has to make predictions on. This can be taken as a proxy to evaluate the memory span of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ylz6HcellL",
        "outputId": "a20248ea-8ed6-48d9-89d3-dd9c5c148982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# A short seed text, not much context given\n",
        "seed = (\"Quantum field theory is the framework that describes physics at the \" \n",
        "        \"miscroscopic scale. In this paper, we \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "present the familiar analysis of semi-infinite graded splitting and actions on suitable isochrones fu\n",
            "analyze the model assuming SU(N_c) gauge theories with the supersymmetry and decay changes to CP even\n",
            "address the topology of a binary system in de Sitter space-time and the ML necessities from the sandw\n",
            "discuss the terminology of some previous questions on truncated spheroid-operator algebras of removal\n",
            "discuss fundamental quantum flows with arbitrarily lare classicality. It is shown that an accelerated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jibHi0D4ex-M",
        "outputId": "8e78d3ad-461c-4396-b9c7-948d5fd6fe4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Medium-sized seed text, some context given\n",
        "seed = (\"Quantum field theory is the framework that describes physics at the \" \n",
        "        \"miscroscopic scale. General relativity, on the other hand, describes \"\n",
        "        \"dynamics of gravity across large distances. These two theories form \"\n",
        "        \"the state-of-the-art of human understanding of the universe. However, \"\n",
        "        \"the Standard Model and Einstein gravity are not compatible at the \"\n",
        "        \"quantum level. In this paper, we \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "provide a new photothe design regularisation approach.A finite temperature transition at C(H) substit\n",
            "consider the model consisting of hypersurfaces to be on an open compact operator, and find that E(B-g\n",
            "propose, assuming smooth Bow Bodies - bounds transform this black hole. From equivalence with the fil\n",
            "provide quantitative evidence that this problem is modelled out by introduction of unbounded modes. W\n",
            "characterize the semilinear phase space description for delocalization of cavity quantum interference\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ira1gC30fNkn",
        "outputId": "7a5f41de-51ba-4cc7-89d1-ba4d85c47f83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Actual abstract from 2011.02926 minus the last sentence.\n",
        "seed = (\"We consider two fundamental long-standing problems in quantum \"\n",
        "        \"chromodynamics (QCD): the origin of color confinement and structure \"\n",
        "        \"of a true vacuum and color singlet quantum states. There is a common \"\n",
        "        \"belief that resolution to these problems needs a knowledge of a \"\n",
        "        \"strict non-perturbative quantum Yang-Mills theory and new ideas. \"\n",
        "        \"Our principal idea in resolving these problems is that structure of \"\n",
        "        \"color confinement and color singlet quantum states must be determined \"\n",
        "        \"by a Weyl symmetry which is an intrinsic symmetry of the Yang-Mills \"\n",
        "        \"gauge theory, and by properties of a selected class of solutions \"\n",
        "        \"satisfying special requirements. Following this idea we construct for \"\n",
        "        \"the first time a space of color singlet one particle quantum states \"\n",
        "        \"for primary colorless gluons and quarks and reveal the structure of \"\n",
        "        \"color confinement in quantum Yang-Mills theory. \"\n",
        "        \"As an application we demonstrate \")\n",
        "        # \"formation of physical observables in a pure QCD, pure glueballs.\")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that the so-called global solution in QCD is established by generating a Josephson exchange (PI) fiel\n",
            "that the second correspondence between two simple clusters with virtual gluons is conserved in shaplo\n",
            "that the CO gate is disregarted as given on by O(1) in terms of the effective masses on full gauge th\n",
            "how the coupling also reproduces the observed anomaly at the internal layers or in angular scales for\n",
            "that the non-classical sources for $P_{1/1}$ perturbations at finite magnetic fields like a real vari\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmBhon8Dobe4"
      },
      "source": [
        "The predictions show relatively weak dependence on context. For short context, 2/5 predictions contain keywords that can be attributed to particle physics. For the medium-context, only 1/5 predictions is related to gravity, while the others do not clearly follow a specific theme. In the long context, all predictions are clearly related to particle physics. Thus, longer contexts help the model to focus in the specific topic of the text, in particular, keywords are generated, instead of more general sentences that could apply to different topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nIhAO4dwFfo"
      },
      "source": [
        "Let's now consider what does the model do when it encounters something completely different from what it has been learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CqpVkJEfgIR",
        "outputId": "62ef955f-c7d7-48ad-f37e-3530b25a2b0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Unrelated string\n",
        "seed = (\"This string does not have to do with science at all, it's a text \"\n",
        "        \"about baby shark. Did you know baby shark is the most watched video \"\n",
        "        \"on Youtube as of November 2020? That is insane, this is because \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "of its matrix identity the Bell inequality. In this work, we use the ladder ensembles of long standin\n",
            "orthogonalization between the Nitrix de Braue allows the source and the coalition properties of the t\n",
            "the view will be measured to be reduced in 1901 up to 95.4 (161 -276-250 km) are re-expressed as dist\n",
            "all elastic control systems which are plausible from the more and most studied form of the classical \n",
            "its separation is between the referee out of the two target features for each case. We provide an alg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaA2nmmXw9oU"
      },
      "source": [
        "It has only been trained on abstracts of scientific articles, thus, of course it does not know how to write sentences in an informal manner and it tends to go back to sciente topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU6QoOU2fpGp",
        "outputId": "2ed03ec3-0d29-45c2-b7c1-af80504449bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Text in another language. The characters have structure (word and sentences) \n",
        "# but the model has never seen these combinations before\n",
        "seed = (\"Este texto esta escrito en otro idioma que el modelo no ha aprendido, \"\n",
        "        \"veamos que pasa si recibe estas palabras raras que no existen en \"\n",
        "        \"ingles. Lo que el modelo predice es que \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time financert' resonances considerable, we concentrate on the seesaw maturity of its operators and t\n",
            "la  \\`on k-fabrideaum d'e de lence immediate & compilator exponentialtion la cettian. To each in plac\n",
            "les problema components - Pont\\citeplete langar of 10 percent t. A molecule removal (ECRT). In this w\n",
            "les variant M column teches corrabolog expression de medistille can communction kernel to pass abstra\n",
            "earths et ap networks under revised Solid Enstreides, bidirectionally coupled them, his semilinear \"s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRflqecBxOo9"
      },
      "source": [
        "The training set is written mostly in English, therefore, the model does not know what to do with text written in another langauge. However, note that some French words appear every now and then, as well as made-up words. It is possible some of the abstracts either were written in or contained French words and the model remembers this. It can somehow tell that this pattern of characters is not English and it trying to replicate non-English sequences it has seen before. However, it has not seen enough non-English examples to really do anything with this. In some sense, the model is 'pretending' to speak another language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpac9nPpf4yk",
        "outputId": "e9f49afc-3727-4c6f-9f36-94c6d8c0e5f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Gibberish\n",
        "seed = (\"m0n923h lxnaefpw;'[kdawpe_dlen;a[ak[k] [';jd0389hufw\")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ol]2ittwavever, both quantum and networks with respect to cluster sizes are also studied.The calculat\n",
            "own]_scot]) = +1.375(8), 1.86523.5853(2). We also show that it was still simple and useful to constru\n",
            "en,8e]In. We will discuss new applications; Zasparefandillo's theory of Schwartz semigroups and canon\n",
            "]^storisate segments under the Uniseneal coupling instead of axiomatized families for the pattern of \n",
            "]+ -> \\mathbf{CP}^{\\infty.})_{n=1}^{+} (in [0,1],\\pi_1|XT_n(x+1)X_2|X_2|I_{n=1}^*;\\leq |\\net{V}}|B|V_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkW2EqgDyU-A"
      },
      "source": [
        "Given gibberish as an input, the model seems to be assuming that this is part of some technical or numeric expression. In particular, see that it tries to close the open parenthesis given in the seed text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4UEjN_7gkPX",
        "outputId": "e3dc353e-c5e6-4d6d-9e80-bd389ecde515",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Does it know how to use question marks?\n",
        "seed = (\"Can naked singularities exist\")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " as well as an elliptic definite. If ${\\mathbb Z}^\\sigma$ and a closed ti bell conjecture, and if the\n",
            ", in fact the media of a compact coordinate group enlible in a symmetric even when such that physical\n",
            " with respect to the geometric structure and details of the technics or as integrator theory on its b\n",
            " at rest of the original precompact abelian function. We give formulas to study the most general disc\n",
            ", thus providing a framework for iteratively carrier more in the theory. In particular, an interestin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5efY6VHy5db"
      },
      "source": [
        "However, it does not introduce question marks when it could be an option. This is because relatively few abstracts contain question marks compared to the bulk of them, thus, this is virtually absent from the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX6oVHrczRD1"
      },
      "source": [
        "Finally, what will it do when it encounters an out-of-vocabular character? Given that we have not taken any precaution to treat this scenario, the answer is obvious, it will throw an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KrMcgbnB2hb",
        "outputId": "9d9a5404-e50a-477a-ec23-8fafb3cd0427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "# OOV test\n",
        "seed = (\"This string contains a character out of vocabulary, the character \"\n",
        "        \"ñ, what will the model do? It predicts the following, \")\n",
        "for k in range(5):\n",
        "  temp = generate_text(model,seed,100)\n",
        "  print(temp)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-c803ccba128f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \"ñ, what will the model do? It predicts the following, \")\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-25a8387b9cbb>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, seed, num_characters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_characters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mseed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_characters\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-25a8387b9cbb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_characters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mseed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_characters\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ñ'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkdDHb8A1ack"
      },
      "source": [
        "Finally, let it predict a long text and watch it make less and less sense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sqpWJlH1dRK"
      },
      "source": [
        "# Actual abstract from 2011.02926 minus the last sentence.\n",
        "seed = (\"We consider two fundamental long-standing problems in quantum \"\n",
        "        \"chromodynamics (QCD): the origin of color confinement and structure \"\n",
        "        \"of a true vacuum and color singlet quantum states. There is a common \"\n",
        "        \"belief that resolution to these problems needs a knowledge of a \"\n",
        "        \"strict non-perturbative quantum Yang-Mills theory and new ideas. \"\n",
        "        \"Our principal idea in resolving these problems is that structure of \"\n",
        "        \"color confinement and color singlet quantum states must be determined \"\n",
        "        \"by a Weyl symmetry which is an intrinsic symmetry of the Yang-Mills \"\n",
        "        \"gauge theory, and by properties of a selected class of solutions \"\n",
        "        \"satisfying special requirements. Following this idea we construct for \"\n",
        "        \"the first time a space of color singlet one particle quantum states \"\n",
        "        \"for primary colorless gluons and quarks and reveal the structure of \"\n",
        "        \"color confinement in quantum Yang-Mills theory. \"\n",
        "        \"As an application we demonstrate \")\n",
        "        # \"formation of physical observables in a pure QCD, pure glueballs.\")\n",
        "temp = generate_text(model,seed,1000)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA7jqfp42C49",
        "outputId": "269e830d-0c70-47d5-dbea-95548ec6e5e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import textwrap\n",
        "print(textwrap.fill(temp,80))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that specifics of the non-Abelian algebra are studied via exact solutions of the\n",
            "\\textit{type} identity theorem for SU(3)Gissilov equations and the Reed-Solomon\n",
            "triples modified Jolan formula and apply this method. We present optimal control\n",
            "of the various dynamical systems that defines the Hamiltonian of the four-state\n",
            "free association a decay of e^+ invariance. Neglecting some other variations on\n",
            "some webs, this negative treatment predicts the general list of Lorentz-\n",
            "invariance. The present work investigates smoothness violations of finite box\n",
            "scattered light in superfields as they share intuitionists.In the framework of\n",
            "nonclassical low bulk systems, we extend the method to deconstruction at the\n",
            "equator of presentation. Here we propose that abstract approaches at seesaw\n",
            "manifolds are obtained for Gowers over knots. We calculate weak actions for the\n",
            "so called \"MacsherWith algebra\". Conservation of secular equations is\n",
            "considered.We explore the phenomenology of a new phase state model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HgK-PPzzjDl"
      },
      "source": [
        "## 6. Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqXVSGTxznuX"
      },
      "source": [
        "We have implemented a simple character-RNN model to generate text trained on abstracts from articles in the arXiv. The model contains an Embedding layer, two layers of LSTMs and a dense fully-connected layer. Given enough training time, this simple architecture can autocomplete words, predict the next word and formulate complete sentences that are syntactically correct. The more context it is given, the more specific its predictions are, as evidenced by the appearance of key words associated to particular scientific areas. When faced with non-scientific text, it will tend to go back to scientific topics, as that is what it has been trained to do. It can recognise when sequences are non-English and non-words, however in these cases it cannot give coherent predictions. Although the spelling and grammar of the predicted text is mostly correct, the model lacks understanding of the topic and does not display long-term memory."
      ]
    }
  ]
}